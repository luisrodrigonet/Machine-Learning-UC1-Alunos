{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b034ff5b",
   "metadata": {},
   "source": [
    "## 💬 RNN - Aplicações Práticas - LPN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b86b5",
   "metadata": {},
   "source": [
    " **Processamento de Linguagem Natural (NLP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ec315",
   "metadata": {},
   "source": [
    "## Análise de Sentimento\n",
    "\n",
    "- Modelo básico de Rede Neural Recorrente (RNN) para uma tarefa de classificação binária de textos, como análise de sentimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b3d7f2",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f2616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c10041",
   "metadata": {},
   "source": [
    "### Carregando os dados - usaremos o dataset IMDB (reviews de filmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32724ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d8320",
   "metadata": {},
   "source": [
    "```python\n",
    "imdb.load_data(num_words=10000)\n",
    "```\n",
    "\n",
    "- Carrega um dataset com 100.000 avaliações de filmes do IMDb.\n",
    "- As palavras nos textos são codificadas como números, onde cada número representa uma palavra específica.\n",
    "- O parâmetro `num_words=10000` mantém apenas as 10.000 palavras mais frequentes no dataset; as demais são ignoradas para simplificar o processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13228d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitando o tamanho das reviews para 500 palavras\n",
    "maxlen = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f4d9c",
   "metadata": {},
   "source": [
    "- Este trecho de código define um comprimento máximo para as sequências de texto e ajusta todas elas a esse tamanho, usando o comando sequence.`pad_sequences`:\n",
    "    - A variável `maxlen = 500` estabelece que cada avaliação (sequência de palavras codificadas) terá no máximo **500 palavras**;\n",
    "    - Se uma avaliação for mais longa, ela será truncada, e se for mais curta, será preenchida com zeros até atingir 500 elementos \n",
    "    - Isso é feito tanto para os dados de treino (`X_train`) quanto para os de teste (`X_test`), garantindo que todas as sequências tenham o mesmo tamanho\n",
    "    - Uma exigência para o funcionamento correto das redes neurais recorrentes durante o treinamento em lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7ac968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=64))  # Codifica as palavras em vetores\n",
    "model.add(SimpleRNN(units=64))  # Camada RNN básica\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Saída: probabilidade de sentimento positivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff50f7",
   "metadata": {},
   "source": [
    "Este trecho **cria um modelo de rede neural recorrente (RNN) simples usando o Keras**, para uma tarefa de classificação binária de textos, como análise de sentimentos:\n",
    "\n",
    "- `Embedding(input_dim=10000, output_dim=64)`:\n",
    "  - Converte as palavras (que são números) em vetores de dimensão 64, criando uma representação densa e significativa para cada palavra.\n",
    "  \n",
    "- `SimpleRNN(units=64)`:\n",
    "  - Camada RNN básica com 64 neurônios, que processa sequências de palavras e mantém uma memória do que foi visto anteriormente.\n",
    "\n",
    "- `Dense(units=1, activation='sigmoid')`:\n",
    "  - Camada de saída que produz uma única saída entre 0 e 1, indicando a probabilidade de a entrada pertencer à classe positiva (por exemplo, sentimento positivo).\n",
    "\n",
    "> Em resumo: este é um modelo básico que **transforma texto em vetores, processa a sequência com memória e retorna uma previsão binária**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0362dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b833b",
   "metadata": {},
   "source": [
    "Este trecho **configura como o modelo será treinado**, definindo:\n",
    "\n",
    "- `loss='binary_crossentropy'`:  \n",
    "  A função de perda usada para medir o erro do modelo em tarefas de **classificação binária** (como determinar se uma avaliação é positiva ou negativa).\n",
    "\n",
    "- `optimizer='adam'`:  \n",
    "  O algoritmo usado para atualizar os pesos da rede durante o treinamento — **Adam** é um otimizador eficiente e amplamente usado.\n",
    "\n",
    "- `metrics=['accuracy']`:  \n",
    "  Define que a **acurácia** (percentual de previsões corretas) será usada como métrica de avaliação durante o treino e teste.\n",
    "\n",
    "**Em resumo**: \n",
    "- este comando diz ao modelo para se preparar para o treinamento usando **Adam** como otimizador, **binary crossentropy** como medida de erro e **acurácia** como forma de avaliar seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd31d3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.6071 - loss: 0.6320 - val_accuracy: 0.8094 - val_loss: 0.4633\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.8168 - loss: 0.4158 - val_accuracy: 0.6870 - val_loss: 0.5851\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.7753 - loss: 0.4881 - val_accuracy: 0.6780 - val_loss: 0.5772\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.7995 - loss: 0.4163 - val_accuracy: 0.7182 - val_loss: 0.5453\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.7598 - loss: 0.4843 - val_accuracy: 0.6372 - val_loss: 0.6336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x288ecb18b00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786bbb90",
   "metadata": {},
   "source": [
    "Este trecho **treina o modelo usando os dados de treino** por um número definido de épocas, com os seguintes detalhes:\n",
    "\n",
    "- `X_train, y_train`:  \n",
    "  São os dados de entrada (sequências de texto) e os respectivos rótulos (0 ou 1 para sentimento negativo ou positivo).\n",
    "\n",
    "- `epochs=5`:  \n",
    "  O modelo será treinado por **5 ciclos completos** sobre todo o conjunto de treinamento.\n",
    "\n",
    "- `batch_size=32`:  \n",
    "  A cada passo do treinamento, o modelo usará **32 amostras** para calcular o erro e atualizar seus pesos.\n",
    "\n",
    "- `validation_split=0.2`:  \n",
    "  Usa **20% dos dados de treino** como conjunto de validação durante o treinamento, para monitorar o desempenho do modelo em dados não vistos durante o ajuste dos pesos.\n",
    "\n",
    "> Em resumo: este comando **treina a rede neural por 5 épocas**, usando lotes de 32 amostras, e a cada época avalia o desempenho com 20% dos dados reservados para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7e4ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6395 - loss: 0.6384\n",
      "Acurácia no conjunto de teste: 63.86%\n"
     ]
    }
   ],
   "source": [
    "# Avaliação no conjunto de teste\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4671fdb",
   "metadata": {},
   "source": [
    "Este trecho **avalia o desempenho do modelo treinado no conjunto de teste**, ou seja, em dados que ele **nunca viu durante o treinamento**:\n",
    "\n",
    "- `model.evaluate(X_test, y_test)`:\n",
    "  - Calcula a **perda (loss)** e a **acurácia (accuracy)** do modelo nos dados de teste.\n",
    "  \n",
    "- `loss, accuracy = ...`:\n",
    "  - Armazena os valores de erro e acerto do modelo nas variáveis `loss` e `accuracy`.\n",
    "\n",
    "- `print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')`:\n",
    "  - Exibe a **acurácia em porcentagem**, com duas casas decimais, para facilitar a interpretação.\n",
    "\n",
    "📌 **Resumo**: Este código testa o modelo com dados novos e mostra **quão bem ele generaliza**, ou seja, como ele se sairá em situações reais com dados desconhecidos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine Learning (venv)",
   "language": "python",
   "name": "ml_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
