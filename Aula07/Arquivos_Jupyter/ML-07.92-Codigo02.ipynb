{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0185623d",
   "metadata": {},
   "source": [
    "# Introdu√ß√£o √†s Redes Neurais com PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0888e",
   "metadata": {},
   "source": [
    "## Objetivo da Aula:\n",
    "\n",
    "Nesta aula, vamos explorar passo a passo o funcionamento de uma rede neural artificial para **classifica√ß√£o bin√°ria** utilizando a biblioteca **PyTorch**. O c√≥digo fornecido ser√° usado como exemplo pr√°tico para entender cada etapa do processo de constru√ß√£o e treinamento de um modelo de aprendizado profundo (*deep learning*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ab919",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o ao Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9801e",
   "metadata": {},
   "source": [
    "O objetivo √© criar um classificador bin√°rio que aprenda a prever se a soma de duas vari√°veis aleat√≥rias √© maior que 1.\n",
    "\n",
    "> **Exemplo de regra:**  \n",
    "> - Se $ x_1 + x_2 > 1 \\Rightarrow y = 1 $ (classe positiva)  \n",
    "> - Caso contr√°rio, $ y = 0 $ (classe negativa)\n",
    "\n",
    "Esse tipo de problema pode ser resolvido com modelos lineares simples, mas usaremos uma rede neural mais complexa para fins did√°ticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fadd19f",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fde56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f83bb",
   "metadata": {},
   "source": [
    "## Gera√ß√£o dos Dados Sint√©ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce3c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_data = np.random.rand(200, 2)  # 200 amostras, 2 features\n",
    "y_data = (X_data[:,0] + X_data[:,1] > 1.0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823000f",
   "metadata": {},
   "source": [
    "### Explica√ß√£o:\n",
    "\n",
    " Ex.: y=1 se (x1 + x2 > 1.0), caso contr√°rio y=0 (uma l√≥gica simples).\n",
    "\n",
    "- `np.random.rand(200, 2)` gera 200 pares de n√∫meros entre 0 e 1.\n",
    "- A linha `(X_data[:,0] + X_data[:,1] > 1.0).astype(int)` cria r√≥tulos bin√°rios com base na regra definida.\n",
    "\n",
    "üìå **Objetivo do seed**: Garantir reprodutibilidade dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b578ad",
   "metadata": {},
   "source": [
    "## Divis√£o em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac73f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9beaf12",
   "metadata": {},
   "source": [
    "### Explica√ß√£o:\n",
    "- Usamos `train_test_split` do `sklearn.model_selection` para dividir os dados em:\n",
    "  - 70% para **treino**\n",
    "  - 30% para **teste**\n",
    "- Isso evita que o modelo memorize os dados e garante que ele generalize bem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7733e19",
   "metadata": {},
   "source": [
    "## Convers√£o para Tensores do PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "673076a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f705d",
   "metadata": {},
   "source": [
    "### Explica√ß√£o:\n",
    "- O PyTorch trabalha com tensores (`torch.Tensor`) em vez de arrays NumPy.\n",
    "- `.view(-1,1)` transforma o vetor de r√≥tulos em uma coluna (formato exigido pela fun√ß√£o de perda)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7cf6e",
   "metadata": {},
   "source": [
    "## Defini√ß√£o da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d386541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedNet(nn.Module):\n",
    "    def __init__(self, input_dim=2):\n",
    "        super(AdvancedNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8, 4)\n",
    "        self.fc3 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70443f99",
   "metadata": {},
   "source": [
    "### Estrutura da Rede:\n",
    "| Camada | Fun√ß√£o |\n",
    "|--------|--------|\n",
    "| `fc1`: Linear(2 ‚Üí 8) | Primeira camada oculta |\n",
    "| `ReLU` | Fun√ß√£o de ativa√ß√£o n√£o linear |\n",
    "| `fc2`: Linear(8 ‚Üí 4) | Segunda camada oculta |\n",
    "| `ReLU` | Nova ativa√ß√£o |\n",
    "| `fc3`: Linear(4 ‚Üí 1) | Camada de sa√≠da (logits) |\n",
    "\n",
    "üí° **Importante**: N√£o aplicamos `sigmoid` no final porque usaremos `BCEWithLogitsLoss`, que inclui isso internamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b667b",
   "metadata": {},
   "source": [
    "## Criando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30be5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdvancedNet(input_dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1164226",
   "metadata": {},
   "source": [
    "## Fun√ß√£o de Perda e Otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a2d7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fc26f",
   "metadata": {},
   "source": [
    "### Explica√ß√£o:\n",
    "\n",
    "- **`BCEWithLogitsLoss`**:\n",
    "  - Combina `Sigmoid` + `Binary Cross Entropy Loss`.\n",
    "  - Ideal para problemas de classifica√ß√£o bin√°ria.\n",
    "- **`Adam`**:\n",
    "  - Um otimizador adaptativo que ajusta automaticamente as taxas de aprendizado.\n",
    "  - Mais eficiente que o SGD cl√°ssico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7626c",
   "metadata": {},
   "source": [
    "## Loop de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d34922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âpoca 5/20, Perda Treino: 0.6933\n",
      "√âpoca 10/20, Perda Treino: 0.6792\n",
      "√âpoca 15/20, Perda Treino: 0.6683\n",
      "√âpoca 20/20, Perda Treino: 0.6538\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    outputs = model(X_train_t)\n",
    "    loss = criterion(outputs, y_train_t)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"√âpoca {epoch+1}/{epochs}, Perda Treino: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185464e",
   "metadata": {},
   "source": [
    "### Etapas do Treinamento:\n",
    "\n",
    "1. **Forward pass**: Calcula a sa√≠da do modelo.\n",
    "2. **C√°lculo da perda**: Compara previs√£o com valor real.\n",
    "3. **Backward pass (backpropagation)**: Calcula gradientes.\n",
    "4. **Atualiza√ß√£o dos pesos**: Usa o otimizador para ajustar os par√¢metros.\n",
    "\n",
    "üìå **Dica**: Imprimir a perda a cada poucas √©pocas ajuda a monitorar o progresso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867915d9",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f1f9770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acur√°cia no teste: 50.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits_test = model(X_test_t)\n",
    "    probs_test = torch.sigmoid(logits_test)\n",
    "    preds_test = (probs_test > 0.5).float()\n",
    "\n",
    "    acc = accuracy_score(y_test_t.numpy(), preds_test.numpy())\n",
    "    print(f\"\\nAcur√°cia no teste: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f03e6e",
   "metadata": {},
   "source": [
    "### Explica√ß√£o:\n",
    "\n",
    "- `torch.no_grad()` desativa o c√°lculo de gradientes (economiza mem√≥ria).\n",
    "- `torch.sigmoid` converte os *logits* para probabilidades entre 0 e 1.\n",
    "- `preds_test = (probs_test > 0.5).float()` aplica o limiar de decis√£o.\n",
    "- Usamos `accuracy_score` do `sklearn.metrics` para medir a acur√°cia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2fb28",
   "metadata": {},
   "source": [
    "## Considera√ß√µes Finais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb9df2",
   "metadata": {},
   "source": [
    "### Pontos-Chave Abordados:\n",
    "\n",
    "- Como gerar dados sint√©ticos para aprendizado supervisionado.\n",
    "- Como preparar os dados para uso no PyTorch.\n",
    "- Estrutura b√°sica de uma rede neural feedforward.\n",
    "- Uso de fun√ß√µes de ativa√ß√£o (ReLU) e camadas densas (Linear).\n",
    "- Uso de BCEWithLogitsLoss para classifica√ß√£o bin√°ria.\n",
    "- Implementa√ß√£o do loop de treinamento com Adam.\n",
    "- Avalia√ß√£o de desempenho com acur√°cia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a20488",
   "metadata": {},
   "source": [
    "### Sugest√µes para Pr√≥ximos Passos:\n",
    "\n",
    "- Adicionar regulariza√ß√£o (Dropout, L2).\n",
    "- Experimentar diferentes arquiteturas.\n",
    "- Visualizar as fronteiras de decis√£o aprendidas.\n",
    "- Trabalhar com conjuntos de dados reais (como Iris ou Breast Cancer do Scikit-learn)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine Learning (venv)",
   "language": "python",
   "name": "ml_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
